# IdeaLens  
A platform to make hackathon judging fair, consistent, and easier at scale.

IdeaLens was built after observing a simple but serious problem in hackathons:  
as the number of teams increases, judging quality becomes harder to maintain.

This is not because judges are careless or unskilled.  
It is because time, attention, and energy are limited.

IdeaLens helps organisers and judges manage this scale better by bringing structure,
consistency, and shared context into the evaluation process — while keeping all final
decisions firmly in human hands.

---

## The Problem We Observed

In most large hackathons:

- Hundreds of teams are evaluated in a short period of time   
- Judges sit through long, back-to-back presentations  
- Early teams get more attention than later ones  
- Presentation skills often matter more than actual implementation  

As a result, two teams with similar work may receive very different outcomes,
depending purely on timing and fatigue.

This is not a judging problem.  
It is a **scaling problem**.

---

## Our Approach

IdeaLens does not attempt to replace judges or automate decisions.

Instead, it focuses on **standardising the process around judges** so that:

- Every team receives similar depth of review  
- Evaluations follow a consistent structure  
- Important details are not missed due to time pressure  
- Judges can focus on understanding the work, not managing context  

The system supports judges by preparing summaries, organising materials,
and guiding structured discussions — nothing more.

---

## How IdeaLens Works

IdeaLens is designed with two clearly separated interfaces.

---

### Team (Participant) Side

Teams interact only with what is relevant to them.

They can:
- Submit their presentation materials
- Track submission and round status
- View feedback after evaluations
- Join interview or discussion sessions
- Receive confirmation when a round is completed
- Download participation certificates after completion



Teams do **not** see internal rankings, scores, or administrative notes.

---

### Admin / Judge Side

The admin interface is designed to reduce manual effort and decision fatigue.

Judges and organisers can:
- View all teams in a single evaluation queue
- See structured summaries of submissions
- Access presentation decks, demo videos, and discussion history
- Track which teams are under review or shortlisted
- Join live sessions when required
- Add private notes or flag teams for further review
- Generate overall reports and summaries

All information is presented in a way that allows quick comparison without rushing decisions.

---

## Evaluation Flow

### Round 1: Presentation Review
Teams submit their pitch decks.

These are reviewed for:
- Clarity of explanation
- Structure of ideas
- Completeness of information

This stage is used only for internal shortlisting.

---

### Round 2: Demo and Discussion
Shortlisted teams provide a demo walkthrough.

Each team is guided through the same set of technical discussion points,
ensuring equal depth and consistency across evaluations.

All interactions are recorded and documented for later reference.

---

### Final Round: Live Interaction
Judges can observe or join live discussions with teams.

They can:
- Ask clarifying questions
- Take over the discussion if required
- Review notes generated during the session

Final decisions are always made by human judges.

---

## Reports and Insights

IdeaLens provides organisers with:
- Total number of teams
- Number of teams evaluated
- Number of teams shortlisted
- Round-wise completion status
- Overall evaluation summaries

Reports can be exported in a clean, data-based format for record keeping.

---

## What IdeaLens Is Not

- It does not automatically select winners  
- It does not expose scores to teams  
- It does not remove human judgment  
- It does not function as a black-box decision system  

Its role is strictly supportive.

---

## Project Status

This project is a hackathon prototype.

It is built to demonstrate:
- A working evaluation flow
- Practical usability for judges
- Responsible use of supporting technology

The focus is on correctness, clarity, and fairness rather than production-level optimisation.

---

## Final Thought

IdeaLens does not decide outcomes.

It helps ensure that every team is evaluated with the same attention,
the same structure, and the same level of seriousness — regardless of when they present.
